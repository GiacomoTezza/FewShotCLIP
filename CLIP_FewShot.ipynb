{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7ImPOvighMz"
   },
   "source": [
    "# Few-Shot Adaptation of CLIP with CoCoOp for Fine-Grained Flower Classification\n",
    "**Deep Learning Project Assignment 2025**<br>\n",
    "**Team**: Mayora Barcenas Valeria, Tomelleri Jacopo, Tezza Giacomo.\n",
    "\n",
    "## Abstract\n",
    "We introduce a novel extension of CoCoOp for few‑shot adaptation of CLIP ViT‑B/16 on the Oxford Flowers dataset by simultaneously conditioning soft prompts on three complementary signals: image‑dependent tokens, class prototypes, and textual embeddings of encyclopedic flower descriptions; fused via a learned gating mechanism. Experiments on the 10‑shot Flowers102 split show that our multi‑conditioned prompt learner boosts base‑class accuracy to ∼XX.X%, novel‑class accuracy to ∼XX.X%, and harmonic mean to ∼XX.X%, outperforming the standard CoCoOp baseline by approximately X percentage points across all metrics. These results demonstrate that enriching prompt contexts with diverse visual and semantic cues substantially improves fine‑grained few‑shot classification performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "StQmJNoLghM0"
   },
   "source": [
    "## Introduction & Motivation\n",
    "\n",
    "<!-- ##### TODO\n",
    "- Briefly introduce CLIP, few-shot learning, and fine-grained visual recognition.\n",
    "- Introduce the Oxford Flowers dataset and its challenges (subtle inter-class differences, few labeled examples).\n",
    "- State the goal: improving CLIP's zero-shot performance via few-shot adaptation with CoCoOp.\n",
    "- Motivate CoCoOp as the starting method (mention previous results/generalization).\n",
    "- Define your plan: implement CoCoOp → baseline → extend → evaluate → propose future directions. -->\n",
    "\n",
    "Recent advances in vision-language models, most notably CLIP (Contrastive Language–Image Pretraining) \\[Radford et al., 2021], have demonstrated impressive zero-shot generalization across a variety of visual classification tasks. However, for fine-grained domains, where subtle differences separate visually similar classes, zero-shot performance often falls behind methods tailored with task-specific data. Few-shot learning offers a compromise by adapting a pretrained model to new classes using only a handful of labeled examples, thereby combining broad knowledge from large-scale pretraining with targeted, data-efficient adaptation.\n",
    "\n",
    "The Oxford Flowers102 dataset presents a canonical benchmark for fine-grained visual recognition. It comprises 102 flower species, many of which exhibit minimal inter-class variation (e.g. petal shape, color gradations), making discrimination challenging. Furthermore, realistic few-shot splits typically allocate as few as 5–10 labeled images per class, further stressing models that must generalize from limited examples.\n",
    "\n",
    "To address these challenges, we aim to improve CLIP’s zero-shot performance on Flowers102 via few-shot adaptation. We build upon CoCoOp (Conditional Context Optimization) \\[Zhou et al., 2022], a state-of-the-art prompt-learning method that learns soft prompts conditioned on input images to bridge the gap between image features and language-based classifiers. CoCoOp has demonstrated superior generalization to unseen classes compared to fixed or manually designed prompts, making it an ideal baseline for our exploration.\n",
    "\n",
    "Our project plan proceeds as follows:\n",
    "\n",
    "1. **Implement CoCoOp** on CLIP ViT-B/16 and establish baseline performance on the 10-shot Flowers102 split.\n",
    "2. **Extend the prompt learner** by incorporating additional conditioning signals, specifically, class prototypes computed from few-shot examples and textual embeddings derived from encyclopedic flower descriptions.\n",
    "3. **Fuse** these three modalities (image, prototype, text) via a learned gating mechanism to enrich the soft-prompt context.\n",
    "4. **Evaluate** the multi-conditioned prompt learner against standard CoCoOp, comparing base-class accuracy, novel-class accuracy, and their harmonic mean.\n",
    "5. **Analyze** results to identify strengths, limitations, and insights guiding potential future directions. \n",
    "<!-- , such as dynamic prompt lengths or semantic regularization. -->\n",
    "\n",
    "Through this systematic approach, we aim both to demonstrate meaningful gains in fine-grained few-shot classification and to deepen our understanding of how diverse semantic cues can synergize within prompt-learning frameworks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JgX1ILR7ghM0"
   },
   "source": [
    "## Setup and Baseline\n",
    "##### TODO\n",
    "- Environment setup: pip install (all dependencies including clip, torch, tqdm, matplotlib, etc.)\n",
    "- Set seeds for reproducibility\n",
    "- Load the Oxford Flowers dataset (reuse template.py's get_data)\n",
    "    - Show Base/Novel split and explain its purpose (simulate generalization)\n",
    "- Load CLIP (ViT-B/16) and inspect its architecture (input size, vocab, etc.)\n",
    "- Perform CLIP zero-shot evaluation:\n",
    "    - Generate prompts: “a photo of a {flower}, a type of flower”\n",
    "    - Evaluate and report base, novel, and harmonic mean accuracies.\n",
    "- Plot: per-class accuracy bar chart, confusion matrix\n",
    "- Save these metrics for later comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VwTekigDghM0"
   },
   "source": [
    "### Dependencies and Environment Setup\n",
    "This section ensures the notebook is reproducible and fully operational across different environments.<br/>\n",
    "Here it will install all necessary packages, set the working device (CPU/GPU), and configure paths and reproducibility settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T13:19:18.556631Z",
     "iopub.status.busy": "2025-07-16T13:19:18.556339Z",
     "iopub.status.idle": "2025-07-16T13:19:32.434856Z",
     "shell.execute_reply": "2025-07-16T13:19:32.434345Z",
     "shell.execute_reply.started": "2025-07-16T13:19:18.556601Z"
    },
    "id": "VopeGTnSghM1"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", package])\n",
    "\n",
    "install(\"ftfy\")\n",
    "install(\"regex\")\n",
    "install(\"tqdm\")\n",
    "install(\"scikit-learn\")\n",
    "install(\"scikit-image\")\n",
    "install(\"pooch\")\n",
    "install(\"matplotlib\")\n",
    "install(\"pillow\")\n",
    "install(\"openai-clip\")\n",
    "install(\"torch>=2.0\")\n",
    "install(\"torchvision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-07-16T13:19:32.436359Z",
     "iopub.status.busy": "2025-07-16T13:19:32.435999Z",
     "iopub.status.idle": "2025-07-16T13:19:43.852322Z",
     "shell.execute_reply": "2025-07-16T13:19:43.851709Z",
     "shell.execute_reply.started": "2025-07-16T13:19:32.436327Z"
    },
    "id": "QtqdSOr8qqOn",
    "outputId": "188080f0-3d02-4399-d990-65997a1eeb6e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 13:19:36.770590: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-16 13:19:36.909356: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752671976.929976    1447 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752671976.935666    1447 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-16 13:19:36.971816: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "\n",
    "import clip  # OpenAI CLIP\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T13:19:43.854141Z",
     "iopub.status.busy": "2025-07-16T13:19:43.853667Z",
     "iopub.status.idle": "2025-07-16T13:19:43.864937Z",
     "shell.execute_reply": "2025-07-16T13:19:43.862889Z",
     "shell.execute_reply.started": "2025-07-16T13:19:43.854119Z"
    },
    "id": "arDGJv6xghM2"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # Ensure deterministic behavior\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T13:19:43.865890Z",
     "iopub.status.busy": "2025-07-16T13:19:43.865689Z",
     "iopub.status.idle": "2025-07-16T13:19:43.869122Z",
     "shell.execute_reply": "2025-07-16T13:19:43.868637Z",
     "shell.execute_reply.started": "2025-07-16T13:19:43.865872Z"
    },
    "id": "M9V0U92FghM2"
   },
   "outputs": [],
   "source": [
    "# For saving checkpoints, plots, etc.\n",
    "Path(\"outputs\").mkdir(exist_ok=True)\n",
    "Path(\"checkpoints\").mkdir(exist_ok=True)\n",
    "Path(\"logs\").mkdir(exist_ok=True)\n",
    "Path(\"data\").mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2353MHw1p24h"
   },
   "source": [
    "### Dataset Loading and Split\n",
    "Downloading the data directly from torchvision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T13:19:43.872565Z",
     "iopub.status.busy": "2025-07-16T13:19:43.872361Z",
     "iopub.status.idle": "2025-07-16T13:19:43.876054Z",
     "shell.execute_reply": "2025-07-16T13:19:43.875515Z",
     "shell.execute_reply.started": "2025-07-16T13:19:43.872541Z"
    },
    "id": "M_1CrUhZpVCq"
   },
   "outputs": [],
   "source": [
    "def get_data(data_dir=\"./data\", transform=None):\n",
    "    \"\"\"Load Flowers102 train, validation and test sets.\n",
    "    Args:\n",
    "        data_dir (str): Directory where the dataset will be stored.\n",
    "        transform (torch.Compose)\n",
    "    Returns:\n",
    "        tuple: A tuple containing the train, validation, and test sets.\n",
    "    \"\"\"\n",
    "    train = torchvision.datasets.Flowers102(root=data_dir, split=\"train\", download=True, transform=transform)\n",
    "    val = torchvision.datasets.Flowers102(root=data_dir, split=\"val\", download=True, transform=transform)\n",
    "    test = torchvision.datasets.Flowers102(root=data_dir, split=\"test\", download=True, transform=transform)\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KJI_a5EizA5a"
   },
   "source": [
    "#### Base and Novel categories\n",
    "The Oxford Flowers dataset contains 102 classes of flowers. For our experiments, we will split the dataset into base and novel categories.</br>\n",
    "The first 51 classes will be used as base categories, while the remaining 51 classes will be treated as novel categories.</br>\n",
    "This split allows us to simulate a real-world scenario where the model is trained on a set of known categories (base) and evaluated on unseen categories (novel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T13:19:43.878769Z",
     "iopub.status.busy": "2025-07-16T13:19:43.878599Z",
     "iopub.status.idle": "2025-07-16T13:19:43.882128Z",
     "shell.execute_reply": "2025-07-16T13:19:43.881580Z",
     "shell.execute_reply.started": "2025-07-16T13:19:43.878753Z"
    },
    "id": "nfq51vd8q_5a"
   },
   "outputs": [],
   "source": [
    "def base_novel_categories(dataset):\n",
    "    # set returns the unique set of all dataset classes\n",
    "    all_classes = set(dataset._labels)\n",
    "    # and let's count them\n",
    "    num_classes = len(all_classes)\n",
    "\n",
    "    # here list(range(num_classes)) returns a list from 0 to num_classes - 1\n",
    "    # then we slice the list in half and generate base and novel category lists\n",
    "    base_classes = list(range(num_classes))[:num_classes//2]\n",
    "    novel_classes = list(range(num_classes))[num_classes//2:]\n",
    "    return base_classes, novel_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvDdoYQr2fIu"
   },
   "source": [
    "#### Inspect Classes\n",
    "A quick overview of the classes in the dataset, including their names and indices, helps understand and visualize the dataset structure and the split between base and novel categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-07-16T13:19:43.885453Z",
     "iopub.status.busy": "2025-07-16T13:19:43.885184Z",
     "iopub.status.idle": "2025-07-16T13:19:43.960082Z",
     "shell.execute_reply": "2025-07-16T13:19:43.959575Z",
     "shell.execute_reply.started": "2025-07-16T13:19:43.885427Z"
    },
    "id": "veGGpNDctCgR",
    "outputId": "3a95f8a3-5878-41e1-d8d8-ba21390562ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Classes:\n",
      "  0: pink primrose\n",
      "  1: hard-leaved pocket orchid\n",
      "  2: canterbury bells\n",
      "  3: sweet pea\n",
      "  4: english marigold\n",
      "  5: tiger lily\n",
      "  6: moon orchid\n",
      "  7: bird of paradise\n",
      "  8: monkshood\n",
      "  9: globe thistle\n",
      " 10: snapdragon\n",
      " 11: colt's foot\n",
      " 12: king protea\n",
      " 13: spear thistle\n",
      " 14: yellow iris\n",
      " 15: globe-flower\n",
      " 16: purple coneflower\n",
      " 17: peruvian lily\n",
      " 18: balloon flower\n",
      " 19: giant white arum lily\n",
      " 20: fire lily\n",
      " 21: pincushion flower\n",
      " 22: fritillary\n",
      " 23: red ginger\n",
      " 24: grape hyacinth\n",
      " 25: corn poppy\n",
      " 26: prince of wales feathers\n",
      " 27: stemless gentian\n",
      " 28: artichoke\n",
      " 29: sweet william\n",
      " 30: carnation\n",
      " 31: garden phlox\n",
      " 32: love in the mist\n",
      " 33: mexican aster\n",
      " 34: alpine sea holly\n",
      " 35: ruby-lipped cattleya\n",
      " 36: cape flower\n",
      " 37: great masterwort\n",
      " 38: siam tulip\n",
      " 39: lenten rose\n",
      " 40: barbeton daisy\n",
      " 41: daffodil\n",
      " 42: sword lily\n",
      " 43: poinsettia\n",
      " 44: bolero deep blue\n",
      " 45: wallflower\n",
      " 46: marigold\n",
      " 47: buttercup\n",
      " 48: oxeye daisy\n",
      " 49: common dandelion\n",
      " 50: petunia\n",
      "\n",
      "Novel Classes:\n",
      " 51: wild pansy\n",
      " 52: primula\n",
      " 53: sunflower\n",
      " 54: pelargonium\n",
      " 55: bishop of llandaff\n",
      " 56: gaura\n",
      " 57: geranium\n",
      " 58: orange dahlia\n",
      " 59: pink-yellow dahlia?\n",
      " 60: cautleya spicata\n",
      " 61: japanese anemone\n",
      " 62: black-eyed susan\n",
      " 63: silverbush\n",
      " 64: californian poppy\n",
      " 65: osteospermum\n",
      " 66: spring crocus\n",
      " 67: bearded iris\n",
      " 68: windflower\n",
      " 69: tree poppy\n",
      " 70: gazania\n",
      " 71: azalea\n",
      " 72: water lily\n",
      " 73: rose\n",
      " 74: thorn apple\n",
      " 75: morning glory\n",
      " 76: passion flower\n",
      " 77: lotus\n",
      " 78: toad lily\n",
      " 79: anthurium\n",
      " 80: frangipani\n",
      " 81: clematis\n",
      " 82: hibiscus\n",
      " 83: columbine\n",
      " 84: desert-rose\n",
      " 85: tree mallow\n",
      " 86: magnolia\n",
      " 87: cyclamen\n",
      " 88: watercress\n",
      " 89: canna lily\n",
      " 90: hippeastrum\n",
      " 91: bee balm\n",
      " 92: ball moss\n",
      " 93: foxglove\n",
      " 94: bougainvillea\n",
      " 95: camellia\n",
      " 96: mallow\n",
      " 97: mexican petunia\n",
      " 98: bromelia\n",
      " 99: blanket flower\n",
      "100: trumpet creeper\n",
      "101: blackberry lily\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, _, tmp_test = get_data()\n",
    "base_classes, novel_classes = base_novel_categories(tmp_test)\n",
    "CLASS_NAMES = [\"pink primrose\", \"hard-leaved pocket orchid\", \"canterbury bells\", \"sweet pea\", \"english marigold\", \"tiger lily\", \"moon orchid\", \"bird of paradise\", \"monkshood\", \"globe thistle\", \"snapdragon\", \"colt's foot\", \"king protea\", \"spear thistle\", \"yellow iris\", \"globe-flower\", \"purple coneflower\", \"peruvian lily\", \"balloon flower\", \"giant white arum lily\", \"fire lily\", \"pincushion flower\", \"fritillary\", \"red ginger\", \"grape hyacinth\", \"corn poppy\", \"prince of wales feathers\", \"stemless gentian\", \"artichoke\", \"sweet william\", \"carnation\", \"garden phlox\", \"love in the mist\", \"mexican aster\", \"alpine sea holly\", \"ruby-lipped cattleya\", \"cape flower\", \"great masterwort\", \"siam tulip\", \"lenten rose\", \"barbeton daisy\", \"daffodil\", \"sword lily\", \"poinsettia\", \"bolero deep blue\", \"wallflower\", \"marigold\", \"buttercup\", \"oxeye daisy\", \"common dandelion\", \"petunia\", \"wild pansy\", \"primula\", \"sunflower\", \"pelargonium\", \"bishop of llandaff\", \"gaura\", \"geranium\", \"orange dahlia\", \"pink-yellow dahlia?\", \"cautleya spicata\", \"japanese anemone\", \"black-eyed susan\", \"silverbush\", \"californian poppy\", \"osteospermum\", \"spring crocus\", \"bearded iris\", \"windflower\", \"tree poppy\", \"gazania\", \"azalea\", \"water lily\", \"rose\", \"thorn apple\", \"morning glory\", \"passion flower\", \"lotus\", \"toad lily\", \"anthurium\", \"frangipani\", \"clematis\", \"hibiscus\", \"columbine\", \"desert-rose\", \"tree mallow\", \"magnolia\", \"cyclamen\", \"watercress\", \"canna lily\", \"hippeastrum\", \"bee balm\", \"ball moss\", \"foxglove\", \"bougainvillea\", \"camellia\", \"mallow\", \"mexican petunia\", \"bromelia\", \"blanket flower\", \"trumpet creeper\", \"blackberry lily\"]\n",
    "\n",
    "# Pretty formatted print of base and novel classes\n",
    "def print_classes(label, classes, class_names):\n",
    "    print(f\"{label} Classes:\")\n",
    "    for i in classes:\n",
    "        print(f\"{i:3d}: {class_names[i]}\")\n",
    "    print()\n",
    "\n",
    "print_classes(\"Base\", base_classes, CLASS_NAMES)\n",
    "print_classes(\"Novel\", novel_classes, CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8puO1VNpzwvi"
   },
   "source": [
    "#### Split Dataset\n",
    "The dataset is split into base and novel categories using the `base_novel_categories` function. This function takes the dataset and splits it into two subsets: one for base categories and another for novel categories. The split is based on the class indices, ensuring that the first 51 classes are used as base categories and the remaining 51 classes are treated as novel categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T13:19:43.963212Z",
     "iopub.status.busy": "2025-07-16T13:19:43.962918Z",
     "iopub.status.idle": "2025-07-16T13:19:43.967103Z",
     "shell.execute_reply": "2025-07-16T13:19:43.966574Z",
     "shell.execute_reply.started": "2025-07-16T13:19:43.963185Z"
    },
    "id": "msOszMs2zRRu"
   },
   "outputs": [],
   "source": [
    "def split_data(dataset, base_classes):\n",
    "    # these two lists will store the sample indexes\n",
    "    base_categories_samples = []\n",
    "    novel_categories_samples = []\n",
    "\n",
    "    # we create a set of base classes to compute the test below in O(1)\n",
    "    # this is optional and can be removed\n",
    "    base_set = set(base_classes)\n",
    "\n",
    "    # here we iterate over sample labels and also get the correspondent sample index\n",
    "    for sample_id, label in enumerate(dataset._labels):\n",
    "        if label in base_set:\n",
    "            base_categories_samples.append(sample_id)\n",
    "        else:\n",
    "            novel_categories_samples.append(sample_id)\n",
    "\n",
    "    # here we create the dataset subsets\n",
    "    # the torch Subset is just a wrapper around the dataset\n",
    "    # it simply stores the subset indexes and the original dataset (your_subset.dataset)\n",
    "    # when asking for sample i in the subset, torch will look for its original position in the dataset and retrieve it\n",
    "    # https://pytorch.org/docs/stable/data.html#torch.utils.data.Subset\n",
    "    base_dataset = torch.utils.data.Subset(dataset, base_categories_samples)\n",
    "    novel_dataset = torch.utils.data.Subset(dataset, novel_categories_samples)\n",
    "    return base_dataset, novel_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQZT22rE8hBw"
   },
   "source": [
    "#### Extract k shots\n",
    "The dataset already provides 10 train and validation shots, so we do not need to extract them. In many few-shot adaptation papers, this operation is necessary as most datasets contain significantly more samples in both the training and validation sets. However, in our case, we can directly utilize the provided shots without further extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KpbPRLr7WL_"
   },
   "source": [
    "### CLIP (ViT-B/16) Loading and Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-07-16T13:19:43.972385Z",
     "iopub.status.busy": "2025-07-16T13:19:43.972211Z",
     "iopub.status.idle": "2025-07-16T13:19:49.700103Z",
     "shell.execute_reply": "2025-07-16T13:19:49.699496Z",
     "shell.execute_reply.started": "2025-07-16T13:19:43.972369Z"
    },
    "id": "Sh6uLZRT7YJx",
    "outputId": "e695fe2f-32b0-419e-b8c4-de5a8eadcacf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    Resize(size=224, interpolation=bicubic, max_size=None, antialias=True)\n",
       "    CenterCrop(size=(224, 224))\n",
       "    <function _convert_image_to_rgb at 0x7f8ebe91e020>\n",
       "    ToTensor()\n",
       "    Normalize(mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711))\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# available models = ['RN50', 'RN101', 'RN50x4', 'RN50x16', 'RN50x64', 'ViT-B/32', 'ViT-B/16', 'ViT-L/14', 'ViT-L/14@336px']\n",
    "model, preprocess = clip.load(\"ViT-B/16\", device=device)\n",
    "\n",
    "# preprocess contains CLIP's pre-defined augmentations, let's inspect them!\n",
    "preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lM9H14899ses"
   },
   "source": [
    "#### Load and Prepare Data\n",
    "Before we can compute the CLIP zero-shot performance, that will be our baseline, we need to load the dataset and prepare it for evaluation. This involves applying CLIP's predefined augmentations and splitting the dataset into base and novel categories, as described in the previous sections.</br>\n",
    "For the zero-shot evaluation, we need the novel categories only for the test set, so we will drop `train_novel` and `val_novel` datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T13:19:49.702970Z",
     "iopub.status.busy": "2025-07-16T13:19:49.702779Z",
     "iopub.status.idle": "2025-07-16T13:19:49.729195Z",
     "shell.execute_reply": "2025-07-16T13:19:49.728714Z",
     "shell.execute_reply.started": "2025-07-16T13:19:49.702952Z"
    },
    "id": "TVrYUYTv9ttM"
   },
   "outputs": [],
   "source": [
    "# get the three datasets\n",
    "train_set, val_set, test_set = get_data(transform=preprocess)\n",
    "\n",
    "# split classes into base and novel\n",
    "base_classes, novel_classes = base_novel_categories(train_set)\n",
    "\n",
    "# split the three datasets\n",
    "train_base, _ = split_data(train_set, base_classes)\n",
    "val_base, _ = split_data(val_set, base_classes)\n",
    "test_base, test_novel = split_data(test_set, base_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YcgMwr3J9VIg"
   },
   "source": [
    "### Compute Zero-Shot Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 526
    },
    "execution": {
     "iopub.execute_input": "2025-07-16T13:19:49.732288Z",
     "iopub.status.busy": "2025-07-16T13:19:49.732069Z",
     "iopub.status.idle": "2025-07-16T13:19:49.737660Z",
     "shell.execute_reply": "2025-07-16T13:19:49.737139Z",
     "shell.execute_reply.started": "2025-07-16T13:19:49.732264Z"
    },
    "id": "7uhblkvm9US4",
    "outputId": "dd9a232f-37a7-4229-e133-6a27661cda3d"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad() # we don't want gradients\n",
    "def eval(model, dataset, categories, batch_size, device, label=\"\"):\n",
    "    # let's set the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Remap labels into a contiguous set starting from zero\n",
    "    contig_cat2idx = {cat: idx for idx, cat in enumerate(categories)}\n",
    "\n",
    "    # here we apply the standard CLIP template used for oxford flowers to all categories\n",
    "    # and immediately tokenize each sentence (convert natural language into numbers - feel free to print the text input to inspect them)\n",
    "    text_inputs = clip.tokenize(\n",
    "        [f\"a photo of a {CLASS_NAMES[c]}, a type of flower.\" for c in categories]\n",
    "    ).to(device)\n",
    "\n",
    "    # we can encode the text features once as they are shared for all images\n",
    "    # therefore we do it outside the evaluation loop\n",
    "    text_features = model.encode_text(text_inputs)\n",
    "    # and here we normalize them (standard pratice with CLIP)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    # simple dataloader creation\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    # here we store the number of correct predictions we will make\n",
    "    correct_predictions = 0\n",
    "    for image, target in tqdm(dataloader, desc=label):\n",
    "        # base categories range from 0 to 50, while novel ones from 51 to 101\n",
    "        # therefore we must map categories to the [0, 50], otherwise we will have wrong predictions\n",
    "        # Map targets in contiguous set starting from zero\n",
    "        # Labels needs to be .long() in pytorch\n",
    "        target = torch.Tensor([contig_cat2idx[t.item()] for t in target]).long()\n",
    "\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # forward image through CLIP image encoder\n",
    "        image_features = model.encode_image(image)\n",
    "        # and normalize\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        # here cosine similarity between image and text features and keep the argmax for every row (every image)\n",
    "        predicted_class = (image_features @ text_features.T).argmax(dim=-1)\n",
    "        # now we check which are correct, and sum them (False == 0, True == 1)\n",
    "        correct_predictions += (predicted_class == target).sum().item()\n",
    "\n",
    "    # and now we compute the accuracy\n",
    "    accuracy = correct_predictions / len(dataset)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T13:19:49.738782Z",
     "iopub.status.busy": "2025-07-16T13:19:49.738247Z",
     "iopub.status.idle": "2025-07-16T13:20:19.973637Z",
     "shell.execute_reply": "2025-07-16T13:20:19.972962Z",
     "shell.execute_reply.started": "2025-07-16T13:19:49.738753Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Zero-shot evaluation on Base Classes: 100%|██████████| 20/20 [00:12<00:00,  1.66it/s]\n",
      "🧠 Zero-shot evaluation on Novel Classes: 100%|██████████| 29/29 [00:17<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Base classes accuracy: 71.33%\n",
      "🔍 Novel classes accuracy: 78.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "base_accuracy = eval(model=model, dataset=test_base, categories=base_classes, batch_size=128, device=device, label=\"🧠 Zero-shot evaluation on Base Classes\")\n",
    "novel_accuracy = eval(model=model, dataset=test_novel, categories=novel_classes, batch_size=128, device=device, label=\"🧠 Zero-shot evaluation on Novel Classes\")\n",
    "\n",
    "print()\n",
    "print(f\"🔍 Base classes accuracy: {base_accuracy*100:.2f}%\")\n",
    "print(f\"🔍 Novel classes accuracy: {novel_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "baYfLKNdfbUR"
   },
   "source": [
    "#### Harmonic Mean\n",
    "Few-Shot Adaptations papers usually report the Harmonic Mean.\n",
    "The harmonic mean tends to mitigate the impact of large outliers (base accuracy) and aggravate the impact of small ones (novel accuracy).\n",
    "Thus, achieving very high base accuracies at the expense of the novel accuracy will be penalized by the HM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T13:20:19.976878Z",
     "iopub.status.busy": "2025-07-16T13:20:19.976547Z",
     "iopub.status.idle": "2025-07-16T13:20:19.980559Z",
     "shell.execute_reply": "2025-07-16T13:20:19.980098Z",
     "shell.execute_reply.started": "2025-07-16T13:20:19.976842Z"
    },
    "id": "rKAXR7hlfbUR"
   },
   "outputs": [],
   "source": [
    "def harmonic_mean(base_accuracy, novel_accuracy):\n",
    "    numerator = 2\n",
    "    denominator = 1 / base_accuracy + 1 / novel_accuracy\n",
    "    hm = numerator / denominator\n",
    "    return hm\n",
    "\n",
    "# print(f\"🔍 Harmonic Mean: {harmonic_mean(base_accuracy, novel_accuracy)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTfBAJovghM6"
   },
   "source": [
    "### Baseline evaluation and Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trHBv5NEghM6"
   },
   "source": [
    "## Methodology: CoCoOp\n",
    "<!-- ##### TODO\n",
    "- Provide a short literature summary of CoCoOp with diagram (can be ASCII or markdown)\n",
    "    - What it is (image-conditioned prompt learning)\n",
    "    - Why it helps (avoids overfitting class tokens, learns better generalization)\n",
    "- Describe the architecture:\n",
    "    - MetaNet / PromptLearner: learn image-conditioned soft prompts\n",
    "    - Prompt format: [CLS] + ctx_tokens + class name + EOS\n",
    "    - Only prompt tokens and MetaNet are updated, CLIP remains frozen\n",
    "- Present equations:\n",
    "    - Prompt generation\n",
    "    - Similarity computation\n",
    "    - Cross-entropy loss over cosine similarity\n",
    "- Show a schematic of the training pipeline (optional visual diagram) -->\n",
    "\n",
    "### Overview\n",
    "\n",
    "Conditional Context Optimization (CoCoOp) is an extension of prompt-based adaptation for vision–language models, first introduced by Zhou et al. (2022). Unlike static prompt tuning (e.g. CoOp), which learns a fixed set of soft prompt vectors per class, CoCoOp employs an image-conditioned prompt learner that dynamically generates context embeddings tailored to each input image. This conditional mechanism helps avoid overfitting to class-specific tokens seen during training and yields stronger generalization to novel classes and unseen domains. Empirically, CoCoOp has been shown to improve zero-shot and few-shot transfer performance across a variety of datasets, particularly when there is significant domain shift or fine-grained class structure.\n",
    "\n",
    "### Architecture\n",
    "\n",
    "#### Overview\n",
    "\n",
    "* **Base model:** CLIP ViT-B/16, with its visual encoder $f_v$ and textual encoder $f_t$ frozen.\n",
    "* **PromptLearner (MetaNet):** A small network $g_\\phi$ that takes as input the global image feature and outputs a set of learnable context vectors (“soft prompts”).\n",
    "* **Prompt format:** Each text input to CLIP’s language encoder is constructed as\n",
    "\n",
    "  $$\n",
    "    \\mathbf{p}(x, c) \\;=\\; [\\texttt{[CLS]}] \\;\\oplus\\; \\underbrace{\\mathbf{z}_1 \\oplus \\mathbf{z}_2 \\oplus \\dots \\oplus \\mathbf{z}_M}_{\\text{ctx\\_tokens}} \\;\\oplus\\; \\texttt{“}c\\texttt{”} \\;\\oplus\\; [\\texttt{EOS}]\n",
    "  $$\n",
    "\n",
    "  where $M$ is the number of learned context tokens, $\\mathbf{z}_i\\in\\mathbb{R}^d$ are the soft-prompt embeddings produced by $g_\\phi$, and $c$ is the class name.\n",
    "\n",
    "#### Prompt Learner (MetaNet)\n",
    "\n",
    "* **Input:** Image $x$.\n",
    "\n",
    "* **Visual features:** Extract global feature $\\mathbf{v} = f_v(x)\\in\\mathbb{R}^d$.\n",
    "\n",
    "* **MetaNet:** A two-layer MLP\n",
    "\n",
    "  $$\n",
    "    g_\\phi(\\mathbf{v}) = \\mathrm{MLP}_\\phi(\\mathbf{v}) \\;\\in\\;\\mathbb{R}^{M\\times d}\n",
    "  $$\n",
    "\n",
    "  which outputs the stacked soft prompts $\\{\\mathbf{z}_i\\}_{i=1}^M$.\n",
    "\n",
    "* **Learnable parameters:** $\\phi$ (MetaNet weights) and the soft-prompt embeddings $\\{\\mathbf{z}_i\\}$. The CLIP encoders $f_v$ and $f_t$ remain frozen throughout training.\n",
    "\n",
    "* **Output:** Context tokens $\\mathbf{Z}(x) = [\\mathbf{z}_1(x), \\dots, \\mathbf{z}_M(x)]$.\n",
    "\n",
    "### Mathematical Formulation\n",
    "\n",
    "#### Prompt Generation\n",
    "\n",
    "Given an image $x$ and class name $c$, the prompt learner generates context tokens:\n",
    "\n",
    "$$\n",
    "\\mathbf{Z}(x) = g_\\phi\\bigl(f_v(x)\\bigr) = \\bigl[\\mathbf{z}_1(x), \\dots, \\mathbf{z}_M(x)\\bigr]\n",
    "$$\n",
    "\n",
    "The full token sequence $\\mathbf{P}(x, c)$ is then:\n",
    "\n",
    "$$\n",
    "\\mathbf{P}(x, c) = \\bigl[\\text{[CLS]},\\, \\mathbf{Z}(x),\\, \\text{tokens}(c),\\, \\text{[EOS]}\\bigr]\n",
    "$$\n",
    "\n",
    "#### Similarity Computation\n",
    "\n",
    "1. **Text encoding:**\n",
    "\n",
    "   $$\n",
    "     \\mathbf{t}(x, c) = f_t\\bigl(\\mathbf{P}(x, c)\\bigr)\\in\\mathbb{R}^d\n",
    "   $$\n",
    "2. **Image encoding:**\n",
    "\n",
    "   $$\n",
    "     \\mathbf{v} = f_v(x)\\in\\mathbb{R}^d\n",
    "   $$\n",
    "3. **Cosine similarity:**\n",
    "\n",
    "   $$\n",
    "     s(x,c) \\;=\\; \\cos\\bigl(\\mathbf{v},\\, \\mathbf{t}(x,c)\\bigr)\n",
    "     \\;=\\;\\frac{\\mathbf{v}^\\top \\mathbf{t}(x,c)}{\\|\\mathbf{v}\\|\\,\\|\\mathbf{t}(x,c)\\|}\n",
    "   $$\n",
    "\n",
    "#### Loss Function\n",
    "\n",
    "For a batch of $N$ images $\\{x_i\\}$ with labels $\\{y_i\\}$, we compute logits over the $K$ candidate classes via scaled cosine similarities:\n",
    "\n",
    "$$\n",
    "\\ell_{i,k} \\;=\\; \\tau \\,s\\bigl(x_i,\\,c_k\\bigr)\n",
    "$$\n",
    "\n",
    "where $\\tau$ is a learnable temperature parameter. The cross-entropy loss is\n",
    "\n",
    "$$\n",
    "\\mathcal{L} \\;=\\; -\\frac{1}{N}\\sum_{i=1}^N \\log\\frac{\\exp\\bigl(\\ell_{i,y_i}\\bigr)}{\\sum_{k=1}^K \\exp\\bigl(\\ell_{i,k}\\bigr)}\n",
    "$$\n",
    "\n",
    "Only $\\phi$, the soft-prompt embeddings, and $\\tau$ are updated during training; the CLIP encoders remain fixed.\n",
    "\n",
    "* **Output:** Context tokens $\\mathbf{Z}(x) = [\\mathbf{z}_1(x), \\dots, \\mathbf{z}_M(x)]$\n",
    "\n",
    "### Training Pipeline Schematic\n",
    "\n",
    "```\n",
    "     ┌─────────────────┐\n",
    "     │   Input Image   │\n",
    "     └───┬─────────────┘\n",
    "         │\n",
    "         ▼\n",
    "  ┌───────────────┐\n",
    "  │ Visual Encoder│\n",
    "  │  f_v (frozen) │\n",
    "  └───┬───────────┘\n",
    "      │\n",
    "      │ global feature v\n",
    "      ▼\n",
    "  ┌───────────────┐\n",
    "  │   MetaNet     │\n",
    "  │ g_φ (learned) │\n",
    "  └───┬───────────┘\n",
    "      │ soft prompts Z(x)\n",
    "      ▼\n",
    "Text Prompt Construction:\n",
    "[CLS] ⊕ Z(x) ⊕ “class name” ⊕ [EOS]\n",
    "      │\n",
    "      ▼\n",
    "  ┌───────────────┐\n",
    "  │ Text Encoder  │\n",
    "  │   f_t (frozen)│\n",
    "  └───┬───────────┘\n",
    "      │ text feature t(x,c)\n",
    "      ▼\n",
    "Similarity & Loss:\n",
    "s(x,c) = cos(v, t)\n",
    "Cross-entropy over classes\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwV3pf7YghM6"
   },
   "source": [
    "## Implementation: CoCoOp Baseline\n",
    "<!-- In this section, we implement the CoCoOp (Conditional Context Optimization) method for adapting CLIP to our downstream task. CoCoOp extends the original CoOp approach by generating prompts that are conditioned on the input image. The only trainable components are:\n",
    "\n",
    "- A PromptLearner module that generates learnable context tokens\n",
    "- A small MetaNet (image-conditional MLP) that produces dynamic prompt embeddings\n",
    "\n",
    "We freeze CLIP's visual and text encoders and only train the prompt learner to minimize cross-entropy over the Base training set. -->\n",
    "\n",
    "<!-- ##### TODO\n",
    "- Create PromptLearner module (copy from lab.py and adapt for Oxford Flowers)\n",
    "- Load CLIP\n",
    "- Freeze CLIP weights\n",
    "- Setup train/val/test splits from base classes only\n",
    "- Train PromptLearner on base classes\n",
    "- Use tokenizer and pre-tokenized text prompts for classnames\n",
    "- Implement optimizer, scheduler, and loss function\n",
    "- Report model summary (trainable params)\n",
    "- Show training logs: loss and accuracy curves -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T13:20:19.987492Z",
     "iopub.status.busy": "2025-07-16T13:20:19.987110Z",
     "iopub.status.idle": "2025-07-16T13:20:20.081394Z",
     "shell.execute_reply": "2025-07-16T13:20:20.080898Z",
     "shell.execute_reply.started": "2025-07-16T13:20:19.987464Z"
    },
    "id": "ThDIpaP7ghM6"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "from clip.simple_tokenizer import SimpleTokenizer as _Tokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "_tokenizer = _Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T13:20:20.082271Z",
     "iopub.status.busy": "2025-07-16T13:20:20.082067Z",
     "iopub.status.idle": "2025-07-16T13:20:20.087554Z",
     "shell.execute_reply": "2025-07-16T13:20:20.087043Z",
     "shell.execute_reply.started": "2025-07-16T13:20:20.082253Z"
    },
    "id": "pCo-rRO2ghM6"
   },
   "outputs": [],
   "source": [
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self, clip_model):\n",
    "        super().__init__()\n",
    "        self.transformer = clip_model.transformer\n",
    "        self.positional_embedding = clip_model.positional_embedding\n",
    "        self.ln_final = clip_model.ln_final\n",
    "        self.text_projection = clip_model.text_projection\n",
    "        self.dtype = clip_model.dtype\n",
    "\n",
    "    def forward(self, prompts, tokenized_prompts):\n",
    "        x = prompts.to(self.dtype) + self.positional_embedding.to(self.dtype)\n",
    "        x = x.permute(1, 0, 2)  # NLD -> LND\n",
    "        x = self.transformer(x)\n",
    "        x = x.permute(1, 0, 2)  # LND -> NLD\n",
    "        x = self.ln_final(x).type(self.dtype)\n",
    "\n",
    "        x = x[torch.arange(x.shape[0]), tokenized_prompts.argmax(dim=-1)]\n",
    "        return x @ self.text_projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T13:20:20.088549Z",
     "iopub.status.busy": "2025-07-16T13:20:20.088173Z",
     "iopub.status.idle": "2025-07-16T13:20:20.097301Z",
     "shell.execute_reply": "2025-07-16T13:20:20.096778Z",
     "shell.execute_reply.started": "2025-07-16T13:20:20.088531Z"
    },
    "id": "7f2JfmGbghM7"
   },
   "outputs": [],
   "source": [
    "class PromptLearner(nn.Module):\n",
    "    def __init__(self, class_ids, class_names, clip_model, n_ctx=4, ctx_init=None, device=\"cuda\"):\n",
    "        super().__init__()\n",
    "        self.dtype = clip_model.dtype\n",
    "        ctx_dim = clip_model.ln_final.weight.shape[0]\n",
    "        vis_dim = clip_model.visual.output_dim\n",
    "        self.device = device\n",
    "        self.n_cls = len(class_ids)\n",
    "        self.n_ctx = n_ctx\n",
    "\n",
    "        self.class_ids = class_ids\n",
    "        self.classnames = [class_names[c].replace(\"_\", \" \") for c in class_ids]\n",
    "\n",
    "        if ctx_init:\n",
    "            ctx_init = ctx_init.replace(\"_\", \" \")\n",
    "            n_ctx = len(ctx_init.split(\" \"))\n",
    "            # prompt = clip.tokenize(ctx_init).to(clip_model.token_embedding.weight.device)\n",
    "            prompt = clip.tokenize(ctx_init).to(device)\n",
    "            with torch.no_grad():\n",
    "                embedding = clip_model.token_embedding(prompt).to(self.dtype)\n",
    "            ctx_vectors = embedding[0, 1:1+n_ctx, :]\n",
    "            prompt_prefix = ctx_init\n",
    "        else:\n",
    "            ctx_vectors = torch.empty(n_ctx, ctx_dim, dtype=torch.float32)\n",
    "            nn.init.normal_(ctx_vectors, std=0.02)\n",
    "            prompt_prefix = \" \".join([\"X\"] * n_ctx)\n",
    "\n",
    "        print(f'Initial context: \"{prompt_prefix}\"')\n",
    "        print(f\"# of context tokens: {n_ctx}\")\n",
    "\n",
    "        self.ctx = nn.Parameter(ctx_vectors)\n",
    "\n",
    "        self.meta_net = nn.Sequential(OrderedDict([\n",
    "            (\"linear1\", nn.Linear(vis_dim, vis_dim // 16)),\n",
    "            (\"relu\", nn.ReLU(inplace=True)),\n",
    "            (\"linear2\", nn.Linear(vis_dim // 16, ctx_dim))\n",
    "        ])).to(device)\n",
    "\n",
    "        prompts = [prompt_prefix + \" \" + name + \".\" for name in self.classnames]\n",
    "        # tokenized = torch.cat([clip.tokenize(p) for p in prompts]).to(clip_model.token_embedding.weight.device)\n",
    "        tokenized = torch.cat([clip.tokenize(p) for p in prompts]).to(device)\n",
    "        with torch.no_grad():\n",
    "            embedding = clip_model.token_embedding(tokenized).to(self.dtype)\n",
    "\n",
    "        self.register_buffer(\"token_prefix\", embedding[:, :1, :]) #SOS\n",
    "        self.register_buffer(\"token_suffix\", embedding[:, 1+n_ctx:, :]) #CLS, EOS\n",
    "        self.tokenized_prompts = tokenized\n",
    "\n",
    "    def construct_prompts(self, ctx, prefix, suffix, label=None):\n",
    "        if label is not None:\n",
    "            prefix = prefix[label]\n",
    "            suffix = suffix[label]\n",
    "        return torch.cat([prefix, ctx, suffix], dim=1)\n",
    "\n",
    "    def forward(self, image_features):\n",
    "        B = image_features.shape[0]\n",
    "        ctx = self.ctx.to(self.dtype).unsqueeze(0)                # (1, n_ctx, dim)\n",
    "        bias = self.meta_net(image_features.float()).unsqueeze(1)  # (B, 1, dim)\n",
    "        ctx_shifted = ctx + bias                   # (B, n_ctx, dim)\n",
    "\n",
    "        prefix = self.token_prefix\n",
    "        suffix = self.token_suffix\n",
    "\n",
    "        prompts = []\n",
    "        for ctx_i in ctx_shifted:\n",
    "            ctx_exp = ctx_i.unsqueeze(0).expand(self.n_cls, -1, -1)       # (n_cls, n_ctx, dim)\n",
    "            pts = self.construct_prompts(ctx_exp, prefix, suffix)         # (n_cls, ?, dim)\n",
    "            prompts.append(pts)\n",
    "        return torch.stack(prompts)  # (B, n_cls, ?, dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T13:20:20.098205Z",
     "iopub.status.busy": "2025-07-16T13:20:20.097899Z",
     "iopub.status.idle": "2025-07-16T13:20:20.104884Z",
     "shell.execute_reply": "2025-07-16T13:20:20.104403Z",
     "shell.execute_reply.started": "2025-07-16T13:20:20.098187Z"
    },
    "id": "RCAoQDpgghM7"
   },
   "outputs": [],
   "source": [
    "class CoCoOp(nn.Module):\n",
    "    def __init__(self, class_ids, class_names, clip_model, n_ctx=4, ctx_init=None, device=\"cuda\"):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.prompt_learner = PromptLearner(class_ids, class_names, clip_model, n_ctx=n_ctx, ctx_init=ctx_init, device=device).to(device)\n",
    "        self.clip_image_encoder = clip_model.visual\n",
    "        self.clip_text_encoder = clip_model.encode_text\n",
    "        self.text_encoder = TextEncoder(clip_model).to(device)\n",
    "        self.tokenized_prompts = self.prompt_learner.tokenized_prompts\n",
    "        self.logit_scale = clip_model.logit_scale\n",
    "        self.dtype = clip_model.dtype\n",
    "        self.class_ids = class_ids\n",
    "\n",
    "        # Freeze everything except prompt learner\n",
    "        for name, param in self.named_parameters():\n",
    "            if \"prompt_learner\" not in name:\n",
    "                param.requires_grad_(False)\n",
    "\n",
    "        print(f\"Total parameters: {sum(p.numel() for p in self.parameters())}\")\n",
    "        print(f\"Trainable parameters: {sum(p.numel() for p in self.parameters() if p.requires_grad)}\")\n",
    "        print(f\"Trainable parameter percentage: {sum(p.numel() for p in self.parameters() if p.requires_grad) / sum(p.numel() for p in self.parameters()) * 100:.2f}%\")\n",
    "\n",
    "    # For compatibility with the original CLIP interface\n",
    "    def encode_text(self, text_inputs):\n",
    "        return self.clip_text_encoder(text_inputs)\n",
    "\n",
    "    # For compatibility with the original CLIP interface\n",
    "    def encode_image(self, image):\n",
    "        return self.clip_image_encoder(image.to(dtype=self.dtype))\n",
    "\n",
    "    def forward(self, images, labels=None):\n",
    "        images = images.to(self.device).to(self.dtype)\n",
    "        image_features = self.clip_image_encoder(images)\n",
    "        image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        prompts = self.prompt_learner(image_features)\n",
    "\n",
    "        logits = []\n",
    "        for p_i, i_f in zip(prompts, image_features):\n",
    "            text_features = self.text_encoder(p_i, self.tokenized_prompts)\n",
    "            text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "            logit = self.logit_scale.exp() * i_f @ text_features.T\n",
    "            logits.append(logit)\n",
    "        logits = torch.stack(logits)\n",
    "\n",
    "        if self.training and labels is not None:\n",
    "            return F.cross_entropy(logits, labels)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T13:20:20.110193Z",
     "iopub.status.busy": "2025-07-16T13:20:20.109860Z",
     "iopub.status.idle": "2025-07-16T13:20:20.119905Z",
     "shell.execute_reply": "2025-07-16T13:20:20.119404Z",
     "shell.execute_reply.started": "2025-07-16T13:20:20.110175Z"
    },
    "id": "WrbeKo-9wJYJ"
   },
   "outputs": [],
   "source": [
    "def training_step(net, data_loader, optimizer, cost_function, device=\"cuda\", desc=\"Training\"):\n",
    "  samples = 0.0\n",
    "  cumulative_loss = 0.0\n",
    "  cumulative_accuracy = 0.0\n",
    "\n",
    "  net.train()\n",
    "\n",
    "  pbar = tqdm(data_loader, desc=desc, position=0, leave=True, total=len(data_loader))\n",
    "  for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(inputs)\n",
    "    loss = cost_function(outputs, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    samples += inputs.shape[0]\n",
    "    cumulative_loss += loss.item()\n",
    "    _, predicted = outputs.max(dim=1)\n",
    "\n",
    "    cumulative_accuracy += (predicted == targets).sum().item()\n",
    "\n",
    "    pbar.set_postfix(train_loss=loss.item(), train_acc=cumulative_accuracy / samples * 100)\n",
    "    pbar.update(1)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "  return cumulative_loss / samples, cumulative_accuracy /samples * 100\n",
    "\n",
    "\n",
    "def test_step(net, data_loader, cost_function, device=\"cuda\", desc=\"Testing\", categories=None):\n",
    "  samples = 0.0\n",
    "  cumulative_loss = 0.0\n",
    "  cumulative_accuracy = 0.0\n",
    "\n",
    "  net.eval()\n",
    "\n",
    "  # If categories are provided, build mapping for contiguous labels\n",
    "  if categories is not None:\n",
    "    contig_cat2idx = {cat: idx for idx, cat in enumerate(categories)}\n",
    "\n",
    "  pbar = tqdm(data_loader, desc=desc, position=0, leave=True, total=len(data_loader))\n",
    "  with torch.no_grad():\n",
    "    for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
    "      inputs = inputs.to(device)\n",
    "      targets = targets.to(device)\n",
    "\n",
    "      # Remap targets if categories are provided\n",
    "      if categories is not None:\n",
    "        targets = torch.Tensor([contig_cat2idx[t.item()] for t in targets]).long().to(device)\n",
    "\n",
    "      outputs = net(inputs)\n",
    "      loss = cost_function(outputs, targets)\n",
    "      samples += inputs.shape[0]\n",
    "      cumulative_loss += loss.item()\n",
    "      _, predicted = outputs.max(dim=1)\n",
    "\n",
    "      cumulative_accuracy += (predicted == targets).sum().item()\n",
    "\n",
    "      pbar.set_postfix(test_loss=loss.item(), test_acc=cumulative_accuracy / samples * 100)\n",
    "      pbar.update(1)\n",
    "\n",
    "  return cumulative_loss / samples, cumulative_accuracy / samples * 100\n",
    "\n",
    "\n",
    "# A function similar to the test step, but for the novel classes, using a fixed prompt instead of learned prompts\n",
    "def test_novel_step(net, data_loader, cost_function, device=\"cuda\", desc=\"Testing Novel Classes\", categories=None):\n",
    "  samples = 0.0\n",
    "  cumulative_loss = 0.0\n",
    "  cumulative_accuracy = 0.0\n",
    "\n",
    "  net.eval()\n",
    "\n",
    "  # If categories are provided, build mapping for contiguous labels\n",
    "  if categories is not None:\n",
    "    contig_cat2idx = {cat: idx for idx, cat in enumerate(categories)}\n",
    "\n",
    "  # Create a fixed prompt for each novel class\n",
    "  fixed_prompts = clip.tokenize(\n",
    "      [f\"a photo of a {CLASS_NAMES[c]}, a type of flower.\" for c in categories]\n",
    "  ).to(device)\n",
    "  text_features = net.encode_text(fixed_prompts)\n",
    "  text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "  pbar = tqdm(data_loader, desc=desc, position=0, leave=True, total=len(data_loader))\n",
    "  with torch.no_grad():\n",
    "    for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
    "      inputs = inputs.to(device)\n",
    "      targets = targets.to(device)\n",
    "\n",
    "      # Remap targets if categories are provided\n",
    "      if categories is not None:\n",
    "        targets = torch.Tensor([contig_cat2idx[t.item()] for t in targets]).long().to(device)\n",
    "\n",
    "      image_features = net.encode_image(inputs)\n",
    "      image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "      logits = image_features @ text_features.T\n",
    "\n",
    "      loss = cost_function(logits, targets)\n",
    "      samples += inputs.shape[0]\n",
    "      cumulative_loss += loss.item()\n",
    "      _, predicted = logits.max(dim=1)\n",
    "\n",
    "      cumulative_accuracy += (predicted == targets).sum().item()\n",
    "\n",
    "      pbar.set_postfix(test_loss=loss.item(), test_acc=cumulative_accuracy / samples * 100)\n",
    "      pbar.update(1)\n",
    "\n",
    "  return cumulative_loss / samples, cumulative_accuracy / samples * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T13:20:20.120726Z",
     "iopub.status.busy": "2025-07-16T13:20:20.120478Z",
     "iopub.status.idle": "2025-07-16T13:20:20.125251Z",
     "shell.execute_reply": "2025-07-16T13:20:20.124755Z",
     "shell.execute_reply.started": "2025-07-16T13:20:20.120708Z"
    },
    "id": "HM-I2NzmwJXA"
   },
   "outputs": [],
   "source": [
    "def get_optimizer(model, lr, wd, momentum):\n",
    "  optimizer = torch.optim.SGD(\n",
    "      [{\"params\": model.parameters()}],\n",
    "      lr=lr,\n",
    "      momentum=momentum,\n",
    "      weight_decay=wd,\n",
    "      nesterov=True,\n",
    "  )\n",
    "  return optimizer\n",
    "\n",
    "def get_cost_function():\n",
    "  cost_function = torch.nn.CrossEntropyLoss()\n",
    "  return cost_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T13:20:20.126057Z",
     "iopub.status.busy": "2025-07-16T13:20:20.125829Z",
     "iopub.status.idle": "2025-07-16T13:20:25.643958Z",
     "shell.execute_reply": "2025-07-16T13:20:25.643427Z",
     "shell.execute_reply.started": "2025-07-16T13:20:20.126031Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "execution": {
     "iopub.execute_input": "2025-07-16T13:48:09.768244Z",
     "iopub.status.busy": "2025-07-16T13:48:09.767914Z",
     "iopub.status.idle": "2025-07-16T14:10:21.697598Z",
     "shell.execute_reply": "2025-07-16T14:10:21.697048Z",
     "shell.execute_reply.started": "2025-07-16T13:48:09.768218Z"
    },
    "id": "9wF9GErBghM7",
    "outputId": "d360277b-c66d-4aa8-aa4c-28fbcffb89ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 51 classes\n",
      "Initial context: \"X X X X\"\n",
      "# of context tokens: 4\n",
      "Total parameters: 124359201\n",
      "Trainable parameters: 35360\n",
      "Trainable parameter percentage: 0.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 1/15: 100%|██████████| 510/510 [00:56<00:00,  9.04it/s, train_acc=69.2, train_loss=0.247]   \n",
      "Valid Epoch 1/15: 100%|██████████| 510/510 [00:18<00:00, 26.89it/s, test_acc=81.6, test_loss=0.566]   \n",
      "Train Epoch 2/15: 100%|██████████| 510/510 [00:56<00:00,  9.02it/s, train_acc=82, train_loss=0.698]     \n",
      "Valid Epoch 2/15: 100%|██████████| 510/510 [00:18<00:00, 26.86it/s, test_acc=84.3, test_loss=0.35]    \n",
      "Train Epoch 3/15: 100%|██████████| 510/510 [00:56<00:00,  9.01it/s, train_acc=88.4, train_loss=0.00199] \n",
      "Valid Epoch 3/15: 100%|██████████| 510/510 [00:19<00:00, 26.74it/s, test_acc=89.6, test_loss=0.161]   \n",
      "Train Epoch 4/15: 100%|██████████| 510/510 [00:56<00:00,  9.01it/s, train_acc=92.7, train_loss=0.278]   \n",
      "Valid Epoch 4/15: 100%|██████████| 510/510 [00:18<00:00, 26.87it/s, test_acc=90.2, test_loss=0.329]   \n",
      "Train Epoch 5/15: 100%|██████████| 510/510 [00:56<00:00,  9.01it/s, train_acc=92.2, train_loss=0.52]    \n",
      "Valid Epoch 5/15: 100%|██████████| 510/510 [00:19<00:00, 26.83it/s, test_acc=89.4, test_loss=0.0565]  \n",
      "Train Epoch 6/15: 100%|██████████| 510/510 [00:56<00:00,  9.03it/s, train_acc=92.7, train_loss=0.137]   \n",
      "Valid Epoch 6/15: 100%|██████████| 510/510 [00:18<00:00, 26.85it/s, test_acc=89.8, test_loss=0.0777]  \n",
      "Train Epoch 7/15: 100%|██████████| 510/510 [00:56<00:00,  9.02it/s, train_acc=95.5, train_loss=0.0626]  \n",
      "Valid Epoch 7/15: 100%|██████████| 510/510 [00:18<00:00, 26.88it/s, test_acc=89.8, test_loss=0.0352]  \n",
      "Train Epoch 8/15: 100%|██████████| 510/510 [00:56<00:00,  9.01it/s, train_acc=95.7, train_loss=0.00239] \n",
      "Valid Epoch 8/15: 100%|██████████| 510/510 [00:18<00:00, 26.85it/s, test_acc=91.2, test_loss=0.0448]  \n",
      "Train Epoch 9/15: 100%|██████████| 510/510 [00:56<00:00,  9.01it/s, train_acc=96.1, train_loss=0.256]   \n",
      "Valid Epoch 9/15: 100%|██████████| 510/510 [00:18<00:00, 26.86it/s, test_acc=92.5, test_loss=0.0269]  \n",
      "Train Epoch 10/15: 100%|██████████| 510/510 [00:56<00:00,  8.99it/s, train_acc=97.5, train_loss=0.468]   \n",
      "Valid Epoch 10/15: 100%|██████████| 510/510 [00:18<00:00, 26.93it/s, test_acc=91.2, test_loss=0.0181]  \n",
      "Train Epoch 11/15: 100%|██████████| 510/510 [00:56<00:00,  9.02it/s, train_acc=97.1, train_loss=0.1]     \n",
      "Valid Epoch 11/15: 100%|██████████| 510/510 [00:19<00:00, 26.82it/s, test_acc=94.5, test_loss=0.0158]  \n",
      "Train Epoch 12/15: 100%|██████████| 510/510 [00:56<00:00,  9.00it/s, train_acc=97.8, train_loss=7.14e-5] \n",
      "Valid Epoch 12/15: 100%|██████████| 510/510 [00:18<00:00, 26.89it/s, test_acc=93.7, test_loss=0.0116]  \n",
      "Train Epoch 13/15: 100%|██████████| 510/510 [00:56<00:00,  9.02it/s, train_acc=98.6, train_loss=0.0538]  \n",
      "Valid Epoch 13/15: 100%|██████████| 510/510 [00:18<00:00, 26.89it/s, test_acc=93.7, test_loss=0.00978] \n",
      "Train Epoch 14/15: 100%|██████████| 510/510 [00:56<00:00,  9.00it/s, train_acc=99, train_loss=0.0323]    \n",
      "Valid Epoch 14/15: 100%|██████████| 510/510 [00:19<00:00, 26.75it/s, test_acc=92.9, test_loss=0.0113]  \n",
      "Train Epoch 15/15: 100%|██████████| 510/510 [00:56<00:00,  9.02it/s, train_acc=98.8, train_loss=0.00411] \n",
      "Valid Epoch 15/15: 100%|██████████| 510/510 [00:19<00:00, 26.79it/s, test_acc=92.9, test_loss=0.0099]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Val Accuracy: 94.51% at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Train Evaluation: 100%|██████████| 510/510 [00:18<00:00, 26.88it/s, test_acc=99.8, test_loss=0.0608]  \n",
      "Final Valid Evaluation: 100%|██████████| 510/510 [00:18<00:00, 26.85it/s, test_acc=92.9, test_loss=0.0099]  \n",
      "Final Base Evaluation: 100%|██████████| 2473/2473 [01:31<00:00, 26.93it/s, test_acc=93.6, test_loss=0.375]   \n",
      "Final Novel Evaluation: 100%|██████████| 3676/3676 [00:35<00:00, 104.89it/s, test_acc=78.3, test_loss=3.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Training:\n",
      "Train Loss: 0.08850\t\tTrain Accuracy: 99.80392\n",
      "Valid Loss: 0.24666\t\tValid Accuracy: 92.94118\n",
      "Base Loss: 0.24282\t\tBase Accuracy: 93.57056\n",
      "Novel Loss: 3.83736\t\tNovel Accuracy: 78.26442\n",
      "\n",
      "Results:\n",
      "🔍 Base classes accuracy: 93.57%\n",
      "🔍 Novel classes accuracy: 78.26%\n",
      "🔍 Harmonic Mean: 85.24%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main_cocoop(\n",
    "    batch_size=1,\n",
    "    device=\"cuda:0\",\n",
    "    learning_rate=0.002,\n",
    "    weight_decay=0.0005,\n",
    "    momentum=0.9,\n",
    "    epochs=15,\n",
    "    run_name=\"CoCoOp_2\",\n",
    "    n_ctx=4,\n",
    "    ctx_init=None,\n",
    "):\n",
    "    writer = SummaryWriter(f\"runs/{run_name}\")\n",
    "\n",
    "    clip_model, preprocess = clip.load(\"ViT-B/16\", device=device)\n",
    "    train_set, val_set, test_set = get_data(transform=preprocess)\n",
    "    base_classes, novel_classes = base_novel_categories(train_set)\n",
    "    train_base, _ = split_data(train_set, base_classes)\n",
    "    val_base, _ = split_data(val_set, base_classes)\n",
    "    test_base, test_novel = split_data(test_set, base_classes)\n",
    "\n",
    "    print(f\"Training on {len(base_classes)} classes\")\n",
    "\n",
    "    train_loader = DataLoader(train_base, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_base, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    test_loader_base = DataLoader(test_base, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    test_loader_novel = DataLoader(test_novel, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    model = CoCoOp(base_classes, CLASS_NAMES, clip_model, n_ctx=n_ctx, ctx_init=ctx_init, device=device)\n",
    "    optimizer = get_optimizer(model, learning_rate, weight_decay, momentum)\n",
    "    cost_function = get_cost_function()\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accs, val_accs = [], []\n",
    "\n",
    "    # Log hyperparameters\n",
    "    writer.add_hparams(\n",
    "        {\n",
    "            \"batch_size\": batch_size,\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"weight_decay\": weight_decay,\n",
    "            \"momentum\": momentum,\n",
    "            \"epochs\": epochs,\n",
    "            \"n_ctx\": n_ctx,\n",
    "        }, {}\n",
    "    )\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_epoch = -1\n",
    "    checkpoint_path = f\"checkpoints/{run_name}_best.pt\"\n",
    "    last_checkpoint_path = f\"checkpoints/{run_name}_last.pt\"\n",
    "    early_stop_patience = 5\n",
    "    patience_counter = 0\n",
    "\n",
    "    try:\n",
    "        for e in range(epochs):\n",
    "            train_loss, train_acc = training_step(model, train_loader, optimizer, cost_function, device=device, desc=f\"Train Epoch {e+1}/{epochs}\")\n",
    "            val_loss, val_acc = test_step(model, val_loader, cost_function, device=device, desc=f\"Valid Epoch {e+1}/{epochs}\")\n",
    "\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            train_accs.append(train_acc)\n",
    "            val_accs.append(val_acc)\n",
    "\n",
    "            writer.add_scalars(\"Loss\", {\"Train\": train_loss, \"Val\": val_loss}, e)\n",
    "            writer.add_scalars(\"Accuracy\", {\"Train\": train_acc, \"Val\": val_acc}, e)\n",
    "            writer.flush()\n",
    "\n",
    "            # Checkpoint: Save best model\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                best_epoch = e\n",
    "                patience_counter = 0\n",
    "                torch.save({\n",
    "                    'epoch': e,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'val_acc': val_acc,\n",
    "                    'train_acc': train_acc,\n",
    "                    'train_loss': train_loss,\n",
    "                    'val_loss': val_loss,\n",
    "                }, checkpoint_path)\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "\n",
    "            # Save last checkpoint every epoch\n",
    "            torch.save({\n",
    "                'epoch': e,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_acc': val_acc,\n",
    "                'train_acc': train_acc,\n",
    "                'train_loss': train_loss,\n",
    "                'val_loss': val_loss,\n",
    "            }, last_checkpoint_path)\n",
    "\n",
    "            # Early stopping\n",
    "            if patience_counter >= early_stop_patience:\n",
    "                print(f\"Early stopping at epoch {e+1} (no improvement for {early_stop_patience} epochs)\")\n",
    "                break\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Training interrupted. Saving last checkpoint...\")\n",
    "        torch.save({\n",
    "            'epoch': e,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            'train_acc': train_acc,\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "        }, last_checkpoint_path)\n",
    "\n",
    "    print(f\"Best Val Accuracy: {best_val_acc:.2f}% at epoch {best_epoch+1}\")\n",
    "    # prof_eval_base_acc = eval(model, test_base, base_classes, 128, device, label=\"Test Zero Shot on Base\")\n",
    "    # prof_eval_novel_acc = eval(model, test_novel, novel_classes, 128, device, label=\"Test Zero Shot on Novel\")\n",
    "\n",
    "    train_loss, train_acc = test_step(model, train_loader, cost_function, device=device, desc=\"Final Train Evaluation\")\n",
    "    val_loss, val_acc = test_step(model, val_loader, cost_function, device=device, desc=\"Final Valid Evaluation\")\n",
    "    eval_base_loss, eval_base_acc = test_step(model, test_loader_base, cost_function, device=device, desc=\"Final Base Evaluation\", categories=base_classes)\n",
    "    eval_novel_loss, eval_novel_acc = test_novel_step(model, test_loader_novel, cost_function, device=device, desc=\"Final Novel Evaluation\", categories=novel_classes)\n",
    "    hm = harmonic_mean(eval_base_acc, eval_novel_acc)\n",
    "\n",
    "    # Log final metrics\n",
    "    writer.add_scalar(\"Test/Base Accuracy\", eval_base_acc)\n",
    "    writer.add_scalar(\"Test/Novel Accuracy\", eval_novel_acc)\n",
    "    writer.add_scalar(\"Test/Harmonic Mean\", hm)\n",
    "    writer.flush()\n",
    "\n",
    "    print(\"After Training:\")\n",
    "    print(f\"Train Loss: {train_loss:.5f}\\t\\tTrain Accuracy: {train_acc:.5f}\")\n",
    "    print(f\"Valid Loss: {val_loss:.5f}\\t\\tValid Accuracy: {val_acc:.5f}\")\n",
    "    print(f\"Base Loss: {eval_base_loss:.5f}\\t\\tBase Accuracy: {eval_base_acc:.5f}\")\n",
    "    print(f\"Novel Loss: {eval_novel_loss:.5f}\\t\\tNovel Accuracy: {eval_novel_acc:.5f}\")\n",
    "\n",
    "    print(\"\\nResults:\")\n",
    "    print(f\"🔍 Base classes accuracy: {eval_base_acc:.2f}%\")\n",
    "    print(f\"🔍 Novel classes accuracy: {eval_novel_acc:.2f}%\")\n",
    "    print(f\"🔍 Harmonic Mean: {hm:.2f}%\")\n",
    "\n",
    "    # Plot accuracy and loss curves\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(range(epochs), train_losses, label=\"Train Loss\")\n",
    "    plt.plot(range(epochs), val_losses, label=\"Val Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Loss Curve\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(range(epochs), train_accs, label=\"Train Acc\")\n",
    "    plt.plot(range(epochs), val_accs, label=\"Val Acc\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.title(\"Accuracy Curve\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"outputs/{run_name}_curves.png\")\n",
    "    plt.show()\n",
    "\n",
    "    # Log charts to TensorBoard\n",
    "    writer.add_figure(\"Curves\", plt.gcf())\n",
    "    writer.close()\n",
    "\n",
    "main_cocoop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5HXX1FKghM8"
   },
   "source": [
    "## Evaluation: CoCoOp Baseline\n",
    "##### TODO\n",
    "- Evaluate CoCoOp on:\n",
    "    - Base test set (base classes)\n",
    "    - Novel test set (novel classes) — zero-shot generalization\n",
    "- Compute Harmonic Mean\n",
    "- Compare with baseline CLIP (from Section 2)\n",
    "- Show:\n",
    "    - Table with Base, Novel, HM for both CLIP and CoCoOp\n",
    "    - Confusion matrices\n",
    "    - Accuracy per class (bar plots)\n",
    "    - Line plot of train/val curves\n",
    "- Discuss: Where does CoCoOp help most? Are any flowers still confused?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fJ_zpWRkghM8"
   },
   "source": [
    "## Extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJP0e3fwghM8"
   },
   "source": [
    "## Conclusion & Takeaways\n",
    "##### TODO\n",
    "- Summarize performance gains vs. zero-shot\n",
    "- Highlight where CoCoOp shines and its limitations\n",
    "- Discuss extensibility and future work\n",
    "- Reflect on challenges in fine-grained adaptation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sHvnymPyghM8"
   },
   "source": [
    "## References\n",
    "##### TODO\n",
    "- Radford et al., 2021 (CLIP)\n",
    "- Zhou et al., 2022 (CoOp/CoCoOp)\n",
    "- Additional relevant few-shot learning work (e.g., Tip-Adapter, VPT, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J3cLVIqMghM8"
   },
   "source": [
    "## Appendix"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
